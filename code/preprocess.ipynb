{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "from scipy import misc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "img_dir = os.path.abspath('./images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image prepocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !python preprocess_ims.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data/train\"\n",
    "mask_dir = \"../data/train/masks\"\n",
    "img_dir = \"../data/train/images\"\n",
    "mask_path = os.path.join(mask_dir, \"*.png\")\n",
    "img_path = os.path.join(img_dir, \"*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the percent of hero pictures \n",
    "total_files = 0\n",
    "total_hero = 0\n",
    "total_num = 0\n",
    "\n",
    "for file in glob.glob(mask_path):\n",
    "    total_files +=1\n",
    "    img = cv2.imread(file)\n",
    "    blue = img[:,:,0]\n",
    "    green = img[:,0,:]\n",
    "\n",
    "    if np.any(blue == 255):\n",
    "        total_hero += 1\n",
    "    if np.any(blue == 255) or np.any(green == 255):\n",
    "        total_num += 1\n",
    "\n",
    "percent_hero = 100. * total_hero / total_files\n",
    "percent_num = 100. * total_num / total_files\n",
    "\n",
    "print (percent_hero, \"percent of files contain the hero\")\n",
    "print(percent_num, \"percent of files contain people\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete images without people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file is considered as empty file if there are <3 blue and green pixles\n",
    "\n",
    "total_num = 0\n",
    "hero_file_num = 0\n",
    "people_file_num = 0\n",
    "empty_num = 0\n",
    "\n",
    "\n",
    "for file in glob.glob(mask_path):\n",
    "    total_num += 1\n",
    "    img = cv2.imread(file, 1) # BGR img\n",
    "    red = img[:,:,2]\n",
    "    green = img[:,:,1]\n",
    "    blue = img[:,:,0]\n",
    "    \n",
    "    # Count hero & people files num\n",
    "    if np.sum(green) > 255*3:\n",
    "        people_file_num += 1\n",
    "    if np.sum(blue) > 255*3:\n",
    "        hero_file_num += 1  \n",
    "     \n",
    "    # Del empty files\n",
    "    if np.sum(green) < 255*3 and np.sum(blue) < 255*3:\n",
    "        empty_num += 1\n",
    "        # name the train file corresponding to this empty masks file \n",
    "        file_path=file.replace(\"\\\\\",'/').replace('masks','images')\n",
    "        train_name = file_path[:-14] + 'cam1' + file[-10:-3] + 'jpeg'\n",
    "        # another case name without '_'\n",
    "        train_name_1 = file_path[:-15] + 'cam1' + file[-10:-3] + 'jpeg'\n",
    "        \n",
    "        # Del mask files\n",
    "        img_path=file.replace(\"\\\\\",'/')\n",
    "        os.remove(img_path)\n",
    "        \n",
    "        # Del image files\n",
    "        if os.path.exists(train_name):\n",
    "            os.remove(train_name)\n",
    "        elif os.path.exists(train_name_1):\n",
    "            os.remove(train_name_1)\n",
    "        else:\n",
    "            print('did not find the train img: ', train_name)\n",
    "\n",
    "print('Hero files num: ', hero_file_num, '\\nPeople files num: ',people_file_num, '\\nTotal files num: ',total_num)\n",
    "print(empty_num, ' files without people' )\n",
    "print('All empty files have been removed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load resnet152 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Conv2D, Dropout, Activation\n",
    "from keras.layers import MaxPooling2D, AveragePooling2D, Flatten, merge, Reshape #,ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from utils.scale_layer import Scale\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet152_dir = \"../data/weights/resnet152_weights_tf.h5\"\n",
    "resnet152 = Model.load_weights(filepath=resnet152_dir, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 256\n",
    "img_cols = 256\n",
    "num_channel = 3\n",
    "num_classes = 3\n",
    "image_shape = (img_rows, img_cols, num_channel)\n",
    "\n",
    "\n",
    "model = resnet152_model(img_rows, img_cols, num_channel, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    '''The identity_block is the block that has no conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(nb_filter1, 1, 1, name=conv_name_base + '2a', bias=False)(input_tensor)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
    "\n",
    "#     x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
    "    x = Conv2D(nb_filter2, kernel_size=kernel_size, strides=1, padding='same',\n",
    "                      name=conv_name_base + '2b', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
    "\n",
    "    x = Conv2D(nb_filter3, kernel_size=1, strides=1, name=conv_name_base + '2c', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
    "\n",
    "    x = merge([x, input_tensor], mode='sum', name='res' + str(stage) + block)\n",
    "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2,2)):\n",
    "    '''conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(nb_filter1, kernel_size=1, strides=strides,\n",
    "                      name=conv_name_base + '2a', bias=False)(input_tensor)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
    "\n",
    "#     x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
    "    x = Conv2D(nb_filter2, kernel_size=kernel_size, strides=1, padding='same',\n",
    "                      name=conv_name_base + '2b', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
    "\n",
    "    x = Conv2D(nb_filter3, kernel_size=1, strides=1, name=conv_name_base + '2c', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(nb_filter3, kernel_size=1, strides=strides,\n",
    "                             name=conv_name_base + '1', bias=False)(input_tensor)\n",
    "    shortcut = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "    shortcut = Scale(axis=bn_axis, name=scale_name_base + '1')(shortcut)\n",
    "\n",
    "    x = merge([x, shortcut], mode='sum', name='res' + str(stage) + block)\n",
    "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet152_model(img_rows, img_cols, color_type=1, num_classes=None):\n",
    "    \"\"\"\n",
    "    Resnet 152 Model for Keras\n",
    "    Model Schema and layer naming follow that of the original Caffe implementation\n",
    "    https://github.com/KaimingHe/deep-residual-networks\n",
    "    ImageNet Pretrained Weights \n",
    "    Theano: https://drive.google.com/file/d/0Byy2AcGyEVxfZHhUT3lWVWxRN28/view?usp=sharing\n",
    "    TensorFlow: https://drive.google.com/file/d/0Byy2AcGyEVxfeXExMzNNOHpEODg/view?usp=sharing\n",
    "    Parameters:\n",
    "      img_rows, img_cols - resolution of inputs\n",
    "      channel - 1 for grayscale, 3 for color \n",
    "      num_classes - number of class labels for our classification task\n",
    "    \"\"\"\n",
    "    eps = 1.1e-5\n",
    "\n",
    "    # Handle Dimension Ordering for different backends\n",
    "    global bn_axis\n",
    "    \n",
    "    bn_axis = 3\n",
    "    img_input = Input(shape=(img_rows, img_cols, color_type), name='data')\n",
    "#     x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)\n",
    "    x = layers.Conv2D(64, kernel_size=7, strides=2, padding='same', name='conv1', bias=False)(img_input)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Scale(axis=bn_axis, name='scale_conv1')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    for i in range(1,8):\n",
    "        x = identity_block(x, 3, [128, 128, 512], stage=3, block='b'+str(i))\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    for i in range(1,36):\n",
    "        x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b'+str(i))\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    x_fc = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "    x_fc = Flatten()(x_fc)\n",
    "    x_fc = Dense(1000, activation='softmax', name='fc1000')(x_fc)\n",
    "\n",
    "    model = Model(img_input, x_fc)\n",
    "\n",
    "    # Use pre-trained weights for Tensorflow backend\n",
    "    weights_path = \"../data/weights/resnet152_weights_tf.h5\"\n",
    "\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    # Cannot use model.layers.pop() since model is not of Sequential() type\n",
    "    # The method below works since pre-trained weights are stored in layers but not in the model\n",
    "    x_newfc = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "    x_newfc = Flatten()(x_newfc)\n",
    "    x_newfc = Dense(num_classes, activation='softmax', name='fc8')(x_newfc)\n",
    "\n",
    "    model = Model(img_input, x_newfc)\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
